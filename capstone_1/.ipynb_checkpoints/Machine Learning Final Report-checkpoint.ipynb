{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "\n",
    "%pylab inline\n",
    "pylab.rcParams['figure.figsize'] = (20, 6)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#IMPORTING DATA\n",
    "df=pd.read_csv('data/VT-clean.csv',index_col='id',low_memory=False)\n",
    "#print(df.head())\n",
    "#print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_clean=df[['state','stop_date','stop_time','location_raw','county_name','county_fips','fine_grained_location','police_department','driver_gender','driver_age','driver_race','violation','search_conducted','search_type','contraband_found','stop_outcome','is_arrested','officer_id']]\n",
    "#print(df_clean.head())\n",
    "#print(df_clean.info())\n",
    "df_temp=df_clean[pd.notnull(df_clean.stop_outcome)]\n",
    "df_temp=df_temp.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K nearest neighbors\n",
    "\n",
    "In this section I will be using the k nearest neighbors algorithm to predict the stop outcome for a traffic stop from the drivers gender, age, and race.  I will use dummy variables to get ride of the categorical data that I have in my data set and I will use gridsearchsv to tune my parameter for n_neighbors. Lets see how well this algorithm performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.57460174733\n"
     ]
    }
   ],
   "source": [
    "df_learn=df_temp[['driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "y=df_learn['stop_outcome'].values\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for ind,outcome in enumerate(y):\n",
    "    if(outcome=='Written Warning' or outcome =='Verbal Warning'):\n",
    "        y[ind]='Warning'\n",
    "        \n",
    "param_grid = {'n_neighbors':np.arange(3,12)}\n",
    "knn=KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn,param_grid,cv=5)\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n",
    "\n",
    "knn_cv.fit(X_train,y_train)\n",
    "score=knn_cv.score(X_test,y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an accuracy of 57%. This is alright, but lets see if we can get a better score if we add a few more parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.594299472263\n"
     ]
    }
   ],
   "source": [
    "df_learn=df_temp[['violation','contraband_found','driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "y=df_learn['stop_outcome'].values\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for ind,outcome in enumerate(y):\n",
    "    if(outcome=='Written Warning' or outcome =='Verbal Warning'):\n",
    "        y[ind]='Warning'\n",
    "\n",
    "#print(df_x.head())\n",
    "\n",
    "param_grid = {'n_neighbors':np.arange(3,12)}\n",
    "knn=KNeighborsClassifier()\n",
    "knn_cv = GridSearchCV(knn,param_grid,cv=5)\n",
    "\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n",
    "\n",
    "knn_cv.fit(X_train,y_train)\n",
    "score=knn_cv.score(X_test,y_test)\n",
    "\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "including violation and contraband_found columns into our predictive group increases our success level to ~60%. Meaning we can better predict outcomes with those outcomes This still isn't great so now we will try different techniques\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "I will now repeat the same process now with logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.639473236217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_learn=df_temp[['police_department','violation','contraband_found','driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "y=df_learn['stop_outcome'].values\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for ind,outcome in enumerate(y):\n",
    "    if(outcome=='Written Warning' or outcome =='Verbal Warning'):\n",
    "        y[ind]='Warning'\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "param_grid = {'C':[0.01,0.1,1,10,100]}\n",
    "logreg_cv = GridSearchCV(logreg,param_grid,cv=5)\n",
    "\n",
    "\n",
    "\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "score=logreg_cv.score(X_test,y_test)\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With logistic regression we see a significant jump in accuracy to 64%. Still room for improvement so we try again with a different technique.\n",
    "\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.634560665386\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "df_learn=df_temp[['police_department','violation','contraband_found','driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "y=df_learn['stop_outcome'].values\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for ind,outcome in enumerate(y):\n",
    "    if(outcome=='Written Warning' or outcome =='Verbal Warning'):\n",
    "        y[ind]='Warning'\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n",
    "\n",
    "mnb=MultinomialNB()\n",
    "param_grid = {'alpha':[.1, 1, 5, 10, 50]}\n",
    "mnb_cv = GridSearchCV(mnb,param_grid,cv=5)\n",
    "\n",
    "\n",
    "mnb_cv.fit(X_train,y_train)\n",
    "print(mnb_cv.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Naive bayes produces a drop in accuracy to 63%. At this point we have tried multiple machine learning algorithms and we used gridsearchcv to hypertune the necessary parameters. So lastly we will categories stop_outcome into two outcomes rather than 5 outcomes and we will see if logistic regression is more accurately able to predict outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set accuracy: 0.647146497678\n",
      "training set accuracy: 0.646562416401\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "df_learn=df_temp[['police_department','violation','contraband_found','driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "y=df_learn['stop_outcome'].values\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for ind,outcome in enumerate(y):\n",
    "    if(outcome=='Written Warning' or outcome =='Verbal Warning'):\n",
    "        y[ind]='Warning'\n",
    "        \n",
    "    else:\n",
    "        y[ind]='Not Warning'\n",
    "\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=21)\n",
    "\n",
    "logreg=LogisticRegression()\n",
    "param_grid = {'C':[0.01,0.1,1,10,100]}\n",
    "logreg_cv = GridSearchCV(logreg,param_grid,cv=5)\n",
    "\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "score_train=logreg_cv.score(X_train,y_train)\n",
    "score_test=logreg_cv.score(X_test,y_test)\n",
    "\n",
    "print(\"training set accuracy:\",score_train)\n",
    "print(\"training set accuracy:\",score_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that alteration accuracy improved to %65.  \n",
    "\n",
    "\n",
    "## Final Evaluation\n",
    "\n",
    "Overall one could say from this statistic that these features are not good features to use to be able to predict stop outcome. However, if we compare this to just guessing then this model preforms signficantly better than that. Lets now take a look at how well models would do if they guessed one value for all tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage for guessing only Citation 0.3786849065207478\n",
      "Percentage for guessing only Arrest for Violation 0.011782945736434108\n",
      "Percentage for guessing only Written Warning 0.609218422252622\n",
      "Percentage for guessing only Warrant Arrest 0.0002772457820337437\n",
      "Percentage for guessing only Verbal Warning 3.64797081623347e-05\n"
     ]
    }
   ],
   "source": [
    "df_learn=df_temp[['police_department','violation','contraband_found','driver_gender','driver_age','driver_race','stop_outcome']]\n",
    "df_learn=df_learn.dropna()\n",
    "\n",
    "possible_guess=df_learn['stop_outcome'].unique()\n",
    "y=df_learn['stop_outcome'].values\n",
    "\n",
    "df_x=df_learn.drop(['stop_outcome'],axis=1)\n",
    "df_x=pd.get_dummies(df_x,drop_first='true')\n",
    "X=df_x.values\n",
    "\n",
    "for guess in possible_guess:\n",
    "    percentage= len(y[y==guess])/len(y)\n",
    "    print(\"Percentage for guessing only\",guess,percentage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above evaluation we see that our model performs only slightly better than guess Written Warning for all predictions.  This would suggest that there is a slight correlation between the above features and stop outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
